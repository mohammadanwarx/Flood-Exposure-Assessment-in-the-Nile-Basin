{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadfea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flood Exposure Geospatial Pipeline - Exploratory Analysis\n",
    "\n",
    "This notebook demonstrates the key features of the flood exposure geospatial pipeline.\n",
    "\n",
    "## Setup\n",
    "\n",
    "```python\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "from src.io import load_raster, load_vector\n",
    "from src.preprocessing import raster_preprocessing, vector_preprocessing\n",
    "from src.analysis import zonal_statistics, exposure_metrics\n",
    "from src.visualization import maps, plots\n",
    "\n",
    "%matplotlib inline\n",
    "```\n",
    "\n",
    "## 1. Load Sample Data\n",
    "\n",
    "```python\n",
    "# Example: Load flood depth raster\n",
    "# flood_depth, metadata = load_raster.read_geotiff(\"../data/raw/raster/flood_depth.tif\")\n",
    "# print(f\"Raster shape: {flood_depth.shape}\")\n",
    "# print(f\"CRS: {metadata['crs']}\")\n",
    "```\n",
    "\n",
    "## 2. Load Administrative Boundaries\n",
    "\n",
    "```python\n",
    "# Example: Load vector boundaries\n",
    "# boundaries = load_vector.read_shapefile(\"../data/raw/vector/boundaries.shp\")\n",
    "# print(f\"Number of features: {len(boundaries)}\")\n",
    "# print(f\"CRS: {boundaries.crs}\")\n",
    "```\n",
    "\n",
    "## 3. Preprocessing\n",
    "\n",
    "```python\n",
    "# Example: Reproject and clip raster\n",
    "# Ensure boundary and raster have same CRS\n",
    "# if boundaries.crs != metadata['crs']:\n",
    "#     boundaries = boundaries.to_crs(metadata['crs'])\n",
    "```\n",
    "\n",
    "## 4. Zonal Statistics\n",
    "\n",
    "```python\n",
    "# Example: Calculate zonal statistics\n",
    "# stats = zonal_statistics.compute_zonal_statistics(\n",
    "#     \"../data/raw/raster/flood_depth.tif\",\n",
    "#     boundaries,\n",
    "#     stats=['min', 'max', 'mean', 'sum']\n",
    "# )\n",
    "# print(stats.head())\n",
    "```\n",
    "\n",
    "## 5. Exposure Analysis\n",
    "\n",
    "```python\n",
    "# Example: Calculate affected population\n",
    "# population = np.random.rand(100, 100) * 1000  # Dummy population data\n",
    "# flood_depth_array = np.random.rand(100, 100) * 3  # Dummy flood data\n",
    "# \n",
    "# impact = exposure_metrics.calculate_affected_population(\n",
    "#     flood_depth_array,\n",
    "#     population,\n",
    "#     depth_threshold=0.5\n",
    "# )\n",
    "# print(f\"Affected population: {impact['total_affected']:.0f}\")\n",
    "# print(f\"Percentage affected: {impact['percent_affected']:.2f}%\")\n",
    "```\n",
    "\n",
    "## 6. Visualization\n",
    "\n",
    "```python\n",
    "# Example: Plot flood depth map\n",
    "# fig = maps.plot_raster(\n",
    "#     flood_depth[0],\n",
    "#     title=\"Flood Depth (m)\",\n",
    "#     cmap=\"Blues\",\n",
    "#     colorbar_label=\"Depth (m)\"\n",
    "# )\n",
    "# plt.show()\n",
    "```\n",
    "\n",
    "## 7. Time Series Analysis\n",
    "\n",
    "```python\n",
    "# Example: Analyze temporal trends\n",
    "# from src.analysis import time_series\n",
    "# \n",
    "# # Load multiple time steps\n",
    "# file_paths = [\"../data/raw/raster/flood_t1.tif\", \"../data/raw/raster/flood_t2.tif\"]\n",
    "# ts_data = time_series.load_time_series_rasters(file_paths)\n",
    "# \n",
    "# # Calculate temporal statistics\n",
    "# temporal_stats = time_series.calculate_temporal_statistics(ts_data)\n",
    "```\n",
    "\n",
    "## 8. Tensor Operations\n",
    "\n",
    "```python\n",
    "# Example: Use PyTorch for raster processing\n",
    "# from src.tensors import pytorch_ops\n",
    "# \n",
    "# # Apply convolution\n",
    "# kernel = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9.0\n",
    "# smoothed = pytorch_ops.raster_convolution(flood_depth[0], kernel)\n",
    "```\n",
    "\n",
    "## 9. Data Cubes\n",
    "\n",
    "```python\n",
    "# Example: Create and analyze data cubes\n",
    "# from src.cubes import xarray_cube\n",
    "# \n",
    "# # Create datacube\n",
    "# cube = xarray_cube.create_datacube_from_rasters(file_paths)\n",
    "# \n",
    "# # Aggregate temporally\n",
    "# monthly_mean = xarray_cube.aggregate_datacube_temporal(cube, freq='M', method='mean')\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the basic workflow for flood exposure analysis using the geospatial pipeline. Customize and extend these examples for your specific use case.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Load your own data\n",
    "2. Adjust preprocessing parameters\n",
    "3. Calculate exposure metrics for your region\n",
    "4. Generate publication-ready visualizations\n",
    "5. Export results for further analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
